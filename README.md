# Two-step Approach for automatically translating span-dependent datasets - official repo


This repo contains the Datasets reported in the paper and the code required to reproduce them.


## requirements
- Python 3.7 or higher 
 

## Installation

You might want to start by creating a new conda environment for this repo.
```bash
conda ctreate --name <env_name> python=3.7
```


install the required packages (basically just `transformers` and `datasets`)
```bash
pip install -r requirements.txt
```

## Download datasets
To download the larger datasets (3.1 GB) from S3 use the following bash scripts:
```bash
bash data/squad_translated/download.sh          # for the datasets translated by us (1.9 GB)
bash data/xquad_Translated_train/download.sh    # for the datasets translated by XQuAD (1.2 GB)

```
> Note: all datasets are in HuggingFace Format (not original SQuAD format)

## Reproduce results
To reproduce our results you can run training sessions using the compared datasets.
Our trainings were carried on 2 x NVIDIA GeForce RTX 3090 devices. Training on fewer devices or less memory,
might require some modifications to the training recipes.
> If the Scripts are launched not from the root directory of the project, change the `BASEPATH` parameter


### XQuAD Translated-train results
To reproduce our results on the XQuAD Translated-train datasets (evaluation on XQuAD):
```bash
bash scripts/train_xquad_eval_xquad.sh
```
Paper: [On the Cross-lingual Transferability of Monolingual Representations](https://arxiv.org/abs/1910.11856)<br>
GitHub Repository: [XQuAD](https://github.com/deepmind/xquad)
* **Important**: Note that this script will run 10 consecutive training sessions and might take some time 

### Our translation results
To reproduce our results on the datasets generated by us (evaluation on XQuAD):
```bash
bash scripts/train_ours_eval_xquad.sh
```
* **Important**: Note that this script will run 10 consecutive training sessions and might take some time

### Hebrew results
To reproduce our results on the datasets generated by us and on the ParaShoot dataset (evaluation on ParaShoot):
```bash
bash scripts/train_parashoot_eval_parashoot.sh
bash scripts/train_ours_eval_parashoot.sh
```
Paper: [ParaShoot: A Hebrew Question Answering Dataset](https://arxiv.org/abs/2109.11314)<br> 
GitHub Repository: [ParaShoot](https://github.com/omrikeren/ParaShoot) 

### Swedish results
To reproduce our results on the datasets generated by us (evaluation on swedish_squad_dev):
```bash
bash scripts/train_ours_eval_sv_dev_proj.sh
```
Paper: [Building a Swedish Question-Answering Model](https://aclanthology.org/2020.pam-1.16)<br> 
GitHub Repository: [Building a Swedish Question-Answering Model -- Datasets](https://github.com/vottivott/building-a-swedish-qa-model)
* We did not manage to reproduce the results reported in the original paper

### Czech results
To reproduce our results on the datasets generated by us and (evaluation in SQuAD-cs v1.1):
```bash
bash scripts/train_ours_eval_squad_cs.sh
```
Paper: [Reading Comprehension in Czech via Machine Translation and Cross-lingual Transfer](https://arxiv.org/abs/2007.01667)<br>
GitHub Repository: [Czech-Question-Answering](https://github.com/kackamac/Czech-Question-Answering)
* We did not manage to reproduce the results reported in the original paper


